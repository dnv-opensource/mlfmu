# mlfmu

MLFMU serves as a tool for developers looking to integrate machine learning models into simulation environments. It enables the creation of Functional Mock-up Units (FMUs), which are simulation models that adhere to the [FMI standard](https://fmi-standard.org/), from trained machine learning models exported in the [ONNX](https://onnx.ai/) format. The mlfmu package streamlines the process of transforming ONNX models into FMUs, facilitating their use in a wide range of simulation platforms that support the FMI standard such as the [Open Simulation Platform](https://open-simulation-platform.github.io/) or DNV's [Simulation Trust Center](https://store.veracity.com/simulation-trust-center)


## Features
- Compile trained ML models into FMUs (Functional Mock-up Units).
- Easy to integrate in building pipelines.
- Declarative solution, just define what the inputs/outputs/parameters of your co-simulation model should look like and MLFMU will take care of the rest.
- Support for FMU signal vectors in FMI 2.0.
- Advanced customizations by enabling you to change the C++ code of the FMU.

## Installation

```sh
pip install mlfmu
```

## Creating ML FMUs

1. Define the architecture of your ML model and prepare the model to receive the inputs following to MLFMU's input format:

```python
# Training Ketas model
class MlModel(tf.keras.Model):
    ...
    def call(self, inputs):
        inputs, state, time = inputs

        # Do something with the inputs
        outputs = self.layers(inputs)

        return outputs
    ...
```
Note: This example uses a Keras model for demonstration purposes. However, the tool is flexible and can accommodate other frameworks such as PyTorch, TensorFlow, Scikit-learn, and more.

2. Train the model and save it as ONNX file:
```python
import onnx

ml_model = MlModel()
ml_model.compile(loss='mse')
ml_model.fit(training_dataset)

# Save trained model as ONNX at specified path
onnx_model = tf2onnx.convert.from_keras(ml_model)
onnx.save(onnx_model, path/to/save)
```

3. Prepare FMU interface specification:
```json
// Interface.json
{
    "name": "MyMLFMU",
    "description": "A Machine Learning based FMU",
    "usesTime": true,
    "inputs": [
        {
            "name": "input_1",
            "description": "My input signal to the model at position 0",
            "agentInputIndexes": ["0"]
        }
    ],
    "parameters": [
        {
            "name": "parameter_1",
            "description": "My input signal to the model at position 1",
            "agentInputIndexes": ["1"]
        }
    ],
    "outputs": [
        {
            "name": "prediction",
            "description": "The prediction generated by ML model",
            "agentOutputIndexes": ["0"]
        }
    ]
}
```

4. Compile FMU:
```sh
mlfmu build --interface-file Interface.json --model-file model.onnx
```
or if the files is in the current working directory:
```sh
mlfmu build
```

_For more examples and usage, please refer to mlfmu's [documentation][mlfmu_docs]._

## Advanced Usage

### Editing generated FMU source
The command `mlfmu build` will both generate the c++ source code for the mlfmu and compile it automatically. However, it is possible to split this into two steps where it is possible to edit the source code to change the behavior of the resulting FMU.

 ```sh
 mlfmu codegen --interface-file Interface.json --model-file model.onnx --fmu-source-path path/to/generated/source
 ```

This will result in a folder containing the source structured as below.

```
[FmuName]
├── resources
│   └── *.onnx
├── sources
│   ├── fmu.cpp
│   └── model_definitions.h
└── modelDescription.xml
```

Of these generated files it is only recommended to modify `fmu.cpp`.
In this file one can e.g. modify the `DoStep` function of the generated FMU class.

```cpp
class FmuName : public OnnxFmu
{
public:
    FmuName(cppfmu::FMIString fmuResourceLocation)
        : OnnxFmu(fmuResourceLocation)
    { }

    bool DoStep(cppfmu::FMIReal currentCommunicationPoint, cppfmu::FMIReal dt, cppfmu::FMIBoolean newStep,
        cppfmu::FMIReal& endOfStep) override
    {
        // Implement custom behavior here
        // ...

        // Call the base class implementation
        return OnnxFmu::DoStep(currentCommunicationPoint, dt, newStep, endOfStep);
    }
private:
};
```

After doing the modification to the source code one can simply run the `complie` command to complete the process.

```sh
mlfmu compile --fmu-source-path path/to/generated/source
```

### Using class

In addition to the command line interface one can use the same functionality of the tool through a python class.

1. Import `MlFmuBuilder` and create instance of it
```python
from mlfmu.api import MlFmuBuilder
from pathlib import Path

builder = MlFmuBuilder(
    ml_model_file = Path("path/to/model.onnx")
    interface_file = Path("path/to/interface.json")
)
```
2. Call the same commands using the class

- Run `build`

```python
builder.build()
```

- Run `codegen` and then `compile`

```python
builder.generate()

# Do something ...

builder.compile()
```


## Development Setup

1. Install Python 3.9 or higher, i.e. [Python 3.10](https://www.python.org/downloads/release/python-3104/) or [Python 3.11](https://www.python.org/downloads/release/python-3114/)

2. Update pip and setuptools:

    ```sh
    python -m pip install --upgrade pip setuptools
    ```

3. git clone the mlfmu repository into your local development directory:

    ```sh
    git clone https://github.com/dnv-innersource/mlfmu path/to/your/dev/mlfmu
    ```

4. In the mlfmu root folder:

    Create a Python virtual environment:

    ```sh
    python -m venv .venv
    ```

    Activate the virtual environment:

    ..on Windows:

    ```sh
    > .venv\Scripts\activate.bat
    ```

    ..on Linux:

    ```sh
    source .venv/bin/activate
    ```

    Update pip and setuptools:

    ```sh
    (.venv) $ python -m pip install --upgrade pip setuptools
    ```

    (Optional) If you want PyTorch cuda support on your local machine
    (i.e. to use your GPU for torch operations), you should preferably install PyTorch with cuda support first, before installing all other dependendencies.
    On the official [PyTorch website](https://pytorch.org/get-started/locally/)
    you can generate a pip install command matching your local machine's operating system, using a wizard.
    If you are on Windows, the resulting pip install command will most likely look something like this:

    ```sh
    (.venv) $ pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
    ```

    _Hint:_ If you are unsure which cuda version to indicate in above `pip install .. /cuXXX` command, you can use the shell command `nvidia-smi` on your local system to find out the cuda version supported by the current graphics driver installed on your system. When then generating the `pip install` command with the wizard from the [PyTorch website](https://pytorch.org/get-started/locally/), select the cuda version that matches the major version of what your graphics driver supports (major version must match, minor version may deviate).

    Install mlfmu's dependencies. <br>

    ```sh
    (.venv) $ pip install -r requirements-dev.txt
    ```

    This should return without errors.

    Finally, install mlfmu itself, yet not as a regular package but as an _editable_ package instead, using the pip install option -e:

    ```sh
    (.venv) $ pip install -e .
    ```

5. Test that the installation works (in the mlfmu root folder):

    ```sh
    (.venv) $ pytest .
    ```

6. Run an example:

    ```sh
    (.venv) $ cd .\examples\wind_generator\config\
    (.venv) $ mlfmu build
    ```

## Meta

All code in mlfmu is DNV intellectual property and for DNV internal use only.

Copyright (c) 2024 [DNV](https://www.dnv.com) AS. All rights reserved.

Kristoffer Skare - [@LinkedIn](https://www.linkedin.com/in/kristoffer-skare-19606a1a1/) - <kristoffer.skare@dnv.com>

Jorge Luis Mendez - [@LinkedIn](https://www.linkedin.com/in/jorgelmh/) - <jorge.luis.mendez@dnv.com>

Stephanie Kemna - [@LinkedIn](https://www.linkedin.com/in/stephaniekemna/) - <stephanie.kemna@dnv.com>

Author 4 - [@LinkedIn](https://www.linkedin.com/in/name/) - <first.lastname@dnv.com>

```diff
- TODO: (1) Adapt to chosen license (or delete if no license is applied). <br>
- TODO: (2) Adapt or delete the license file (LICENSE.md) <br>
- TODO: (3) Adapt or delete the license entry in setup.cfg <br>
Distributed under the XYZ license. See [LICENSE](LICENSE.md) for more information.
```

[https://github.com/dnv-innersource/mlfmu](https://github.com/dnv-innersource/mlfmu)

## Contributing

1. Fork it (<https://github.com/dnv-innersource/mlfmu/fork>) (Note: this is currently disabled for this repo. For DNV internal development, continue with the next step.)
2. Create an issue in your GitHub repo
3. Create your branch based on the issue number and type (`git checkout -b issue-name`)
4. Evaluate and stage the changes you want to commit (`git add -i`)
5. Commit your changes (`git commit -am 'place a descriptive commit message here'`)
6. Push to the branch (`git push origin issue-name`)
7. Create a new Pull Request in GitHub

For your contribution, please make sure you follow the [STYLEGUIDE](STYLEGUIDE.md) before creating the Pull Request.

<!-- Markdown link & img dfn's -->
[mlfmu_docs]: https://dnv-innersource.github.io/mlfmu/README.html
